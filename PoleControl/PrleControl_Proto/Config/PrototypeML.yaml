behaviors:
  AI_AGENT:
    trainer_type: ppo

    hyperparameters:
      # Hyperparameters common to PPO and SAC
      batch_size: 2048
      buffer_size: 20480
      learning_rate: 3.0e-4
      learning_rate_schedule: linear
      beta: 5.0e-3
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 3

    # Configuration of the neural network (common to PPO/SAC)
    network_settings:
      vis_encoder_type: simple
      normalize: false
      hidden_units: 246
      num_layers: 4
      # memory
      memory:
        sequence_length: 128
        memory_size: 512

    
    # Trainer configurations common to all trainers
    max_steps: 5.0e25
    time_horizon: 64
    summary_freq: 10000
    keep_checkpoints: 5
    checkpoint_interval: 500000000
    threaded: true
    init_path: null


    # # behavior cloning
    #behavioral_cloning:
    #  demo_path: Assets\ML-Agents\Demonstrations/PlayerDemo_0.demo
    #  strength: 0.5
    #  steps: 150000
    #  batch_size: 1024
    #  num_epoch: 3
    #  samples_per_update: 0


    reward_signals:
      # environment reward (default)
      extrinsic:
        strength: 1.0
        gamma: 0.99

     ## GAIL
     # gail:
     #   strength: 0.01
     #   gamma: 0.99
     #   encoding_size: 128
     #   demo_path: Assets\ML-Agents\Demonstrations/PlayerDemo_0.demo
     #   learning_rate: 3.0e-4
     #   #use_actions: false
     #   #use_vail: false

    #time_horizon: 128
    #max_steps: 1.0e7
    #hyperparameters:
    #  batch_size: 128
    #  beta: 0.01
    #  buffer_size: 2048
    #  epsilon: 0.2
    #  lambd: 0.95
    #  learning_rate: 0.0003
    #  num_epoch: 3
    #network_settings:
    #  num_layers: 2
    #  normalize: false
    #  hidden_units: 512
    #reward_signals:
    #  extrinsic:
    #    strength: 1.0
    #    gamma: 0.99
    #  curiosity:
    #    strength: 0.02
    #    gamma: 0.99
    #    network_settings:
    #      hidden_units: 256
    #  gail:
    #    strength: 0.01
    #    gamma: 0.99
    #    demo_path: PrleControl_Proto/Assets\ML-Agents\Demonstrations/Playerandgoal.demo
    #behavioral_cloning:
    #  demo_path: PrleControl_Proto/Assets\ML-Agents\Demonstrations/Playerandgoal.demo
    #  strength: 0.5
    #  steps: 150000

